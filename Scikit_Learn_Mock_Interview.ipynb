{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "As a data scientist at a telecommunications company, you have been tasked with developing a classification model to predict customer churn (cancellation of subscriptions) based on their historical behavior and demographic information. The company wants to understand which customers are likely to churn in order to develop targeted customer retention programs.\n",
        "\n",
        "**Dataset:**\n",
        "You have been provided with a dataset named \"Telco-Customer-Churn.csv\". Each row in the dataset represents a customer, and each column contains attributes related to the customer's services, account information, and demographic details. The dataset includes the following information:\n",
        "\n",
        "1.   Customers who left within the last month (Churn)\n",
        "2.   Services that each customer has signed up for (phone, multiple lines, internet, online security, online backup, device protection, tech support, and streaming TV and movies)\n",
        "3.   Customer account information (how long they've been a customer, contract type, payment method, paperless billing, monthly charges, and total charges)\n",
        "4.   Demographic information about customers (gender, age range, and whether they have partners and dependents)\n",
        "\n",
        "**Objective:**\n",
        "Your task is to develop a classification model that can accurately predict whether a customer is likely to churn based on the available information. The model should be trained on a portion of the dataset and evaluated on the remaining unseen data.\n",
        "\n",
        "**Approach:**\n",
        "1.   Load and preprocess the dataset: Load the dataset and handle any missing values. Encode categorical variables using appropriate encoding techniques.\n",
        "2.   Split the dataset: Split the dataset into training and testing sets to train the model on a subset of data and evaluate its performance on unseen data.\n",
        "3.   Feature scaling: Perform feature scaling on the numerical features to ensure they are on a similar scale, using techniques like StandardScaler.\n",
        "4.   Model selection and training: Train multiple classification models such as K-Nearest Neighbors, Random Forest, Support Vector Machines, and Logistic Regression.\n",
        "5.   Model evaluation: Evaluate the trained models on the testing set using appropriate evaluation metrics such as accuracy.\n",
        "6.   Select the best model: Compare the performance of different models and select the best-performing model based on the chosen evaluation metric.\n",
        "7.   Predict churn: Use the selected model to predict churn for new, unseen data.\n",
        "\n",
        "**Deliverables:**\n",
        "\n",
        "\n",
        "1.   Preprocessed dataset without missing values.\n",
        "2.   Trained classification models with their respective evaluation metrics.\n",
        "3.   The best-performing model for churn prediction.\n",
        "4.   Predictions of churn for new, unseen data.\n",
        "\n",
        "**Note:** The final model can be used by the telecommunications company to identify customers who are likely to churn, enabling them to take proactive measures to retain those customers.\n",
        "\n",
        "Remember to adapt the problem statement and approach as needed, based on any specific requirements or modifications provided by the interviewer or the organization you are applying to."
      ],
      "metadata": {
        "id": "zFxrrWi4pnzR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "data= pd.read_csv('Telco-Customer-Churn.csv')\n",
        "# data.head()\n",
        "labelencoder=LabelEncoder()\n",
        "data['gender']=labelencoder.fit_transform(data['gender'])\n",
        "data['SeniorCitizen']=labelencoder.fit_transform(data['SeniorCitizen'])\n",
        "data['Partner']=labelencoder.fit_transform(data['Partner'])\n",
        "data['Dependents']=labelencoder.fit_transform(data['Dependents'])\n",
        "data['Contract']=labelencoder.fit_transform(data['Contract'])\n",
        "data['PaymentMethod']=labelencoder.fit_transform(data['PaymentMethod'])\n",
        "data['PaperlessBilling']=labelencoder.fit_transform(data['PaperlessBilling'])\n",
        "data['Churn']=labelencoder.fit_transform(data['Churn'])\n",
        "null_count = data['TotalCharges'].isnull().sum()\n",
        "# print(null_count)\n",
        "data['TotalCharges'] = pd.to_numeric(data['TotalCharges'], errors='coerce')\n",
        "# data.dropna(subset=['TotalCharges'], inplace=True)\n",
        "median_total_charges = data['TotalCharges'].median()\n",
        "# print(median_total_charges)\n",
        "data['TotalCharges'].fillna(median_total_charges, inplace=True)\n",
        "X = data[['gender','SeniorCitizen','Partner','Dependents','Contract','PaymentMethod','PaperlessBilling','TotalCharges','MonthlyCharges','tenure']]\n",
        "Y=data['Churn']\n",
        "# print(X.shape[0],Y.shape[0])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42,shuffle=True)\n",
        "reg = LinearRegression().fit(X_train, y_train)\n",
        "Y_pred=reg.predict(X_test)\n",
        "mse = mean_squared_error(y_test, Y_pred)\n",
        "print(\"Mean Squared Error:\", mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7kMgFuvn3dN",
        "outputId": "33d5e028-e533-458d-f04a-05ad8deef08e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.14401522010937384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc=StandardScaler()\n",
        "# numerical_col = data[['tenure', 'MonthlyCharges', 'TotalCharges']]\n",
        "# numerical_features = numerical_col.select_dtypes(include=['int64', 'float64'])\n",
        "# scaled_features = sc.fit_transform(numerical_features)\n",
        "data['tenure']=sc.fit_transform(data[['tenure']])\n",
        "data['MonthlyCharges']=sc.fit_transform(data[['MonthlyCharges']])\n",
        "data['TotalCharges']=sc.fit_transform(data[['TotalCharges']])\n",
        "data.head()\n",
        "\n",
        "X1 = data[['gender','SeniorCitizen','Partner','Dependents','Contract','PaymentMethod','PaperlessBilling','TotalCharges','MonthlyCharges','tenure']]\n",
        "Y1=data['Churn']\n",
        "print(X.shape[0],Y.shape[0])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X1, Y1, test_size=0.33, random_state=42,shuffle=True)\n",
        "reg = LinearRegression().fit(X_train, y_train)\n",
        "Y_pred1=reg.predict(X_test)\n",
        "mse = mean_squared_error(y_test, Y_pred)\n",
        "print(\"Mean Squared Error after standard scaling on numerical category:\", mse)\n",
        "print(\"accuracy after preprocessing ,\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PXg3dHgAi6q",
        "outputId": "1db2b201-6b0b-49e4-cdee-1713be6947c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7043 7043\n",
            "Mean Squared Error after standard scaling on numerical category: 0.1440152201093738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "neigh = KNeighborsClassifier(n_neighbors=9)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X1, Y1, test_size=0.33, random_state=42,shuffle=True)\n",
        "KNN=neigh.fit(X_train, y_train)\n",
        "Y_knn=KNN.predict(X_test)\n",
        "A_KNN=accuracy_score(Y_knn, y_test)\n",
        "print(\"Accuracy on unseen data when KNN model with K =9:\",A_KNN)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34JlW-NS1cYW",
        "outputId": "c7f9c89a-c0a6-4612-96da-183e937a0dfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on unseen data when KNN model with K =3: 0.7819354838709678\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "X_train, X_test, y_train, y_test = train_test_split(X1, Y1, test_size=0.33, random_state=42,shuffle=True)\n",
        "rf = RandomForestClassifier(n_estimators=100,random_state=50)\n",
        "rf.fit(X_train,y_train)\n",
        "Y_rf=rf.predict(X_test)\n",
        "A_rf=accuracy_score(Y_rf, y_test)\n",
        "print(\"Accuracy on unseen data when random foresst classifier is used :\",A_rf)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O32AN3zE3r-F",
        "outputId": "9f86558f-242c-402c-aace-318133adf59f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on unseen data when random foresst classifier is used : 0.7853763440860215\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "X_train, X_test, y_train, y_test = train_test_split(X1, Y1, test_size=0.33, random_state=42,shuffle=True)\n",
        "clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
        "Y_log=clf.predict(X_test)\n",
        "A_log=accuracy_score(Y_log, y_test)\n",
        "print(\"Accuracy on unseen data when logistic regression is used :\",A_log)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D99RkCnz3yKi",
        "outputId": "106e0f63-1937-4038-f25a-6f46f79abfcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on unseen data when logistic regression is used : 0.7995698924731183\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "model=SVC(kernel='linear',C=1)\n",
        "model.fit(X_train,y_train)\n",
        "Y_svc=model.predict(X_test)\n",
        "A_svc=accuracy_score(Y_svc, y_test)\n",
        "print(\"Accuracy on unseen data when SVC  is used :\",A_svc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-vL36sJ6WQP",
        "outputId": "8aca4c6c-781a-4d08-ccc3-0404ecac0c40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on unseen data when SVC  is used : 0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Out of all the models svc performs the best and can used for prediction of churns"
      ],
      "metadata": {
        "id": "9kTrr5T98e1-"
      }
    }
  ]
}